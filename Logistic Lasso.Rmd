---
title: "Logistic Lasso"
author: "Josué Caldas"
date: "2022-07-15"
output: html_document
---

# ====== #
# SET UP #
# ====== #

Llamar a las librerias

```{r}
library(dplyr)
library(plyr)
library(readr)
library(caret)
library(ggplot2)
library(repr)
library(ISLR)
library(haven)
library(jtools)
library(glmnet)
library(broom.mixed)
library(genridge)
library(lmridge)
library(skimr)
library(tidyverse)
library(DataExplorer)
library(scales)
library(corrr)
library(pls)
library(faraway)
library(yarrr)
```

Importar datos

```{r}
datos = read.table("student-por.csv",sep=";",header=TRUE)
# glimpse(data)
```

Seleccionar pocas variables

```{r}
vars = c("Pstatus", "Fedu", "Medu", "famrel", "famsup")
datos = datos[vars]  
```

Observamos los valores unicos

```{r}
unique(datos$Pstatus)
unique(datos$Fedu)
unique(datos$Medu)
unique(datos$famrel)
unique(datos$famsup)
```

Convertir los valores de las variables dicotomicas a 0 1

En el caso de la variable "famsup", yes = 1, no = 0.
En el caso de la variable Pstatus, T = 1, A = 0

```{r}
datos$famsup = ifelse(datos$famsup == "yes", 1, 0)
datos$Pstatus = ifelse(datos$Pstatus == "T", 1, 0)
```


Convertir a las variables "numericas" a categoricas

```{r}
datos$Fedu = as.character(datos$Fedu)
datos$Medu  = as.character(datos$Medu)
datos$famsup  = as.integer(datos$famsup)
datos$Pstatus = as.integer(datos$Pstatus)
datos$famrel = as.character(datos$famrel)
```


Ver la estructura de la data

```{r}
str(datos)
```

Convertir la variable dependiente en vector

```{r}
famsup = as.vector(datos$famsup)
```


Modelar la matriz

```{r}
data_factors = model.matrix(famsup ~ Fedu + Medu + famrel + Pstatus, data = datos) [, -1] # para borrar el intercepto
data         = as.matrix(data.frame(famsup, data_factors))
```

Convertir la matriz a dataframe

```{r}
data = as.data.frame(data)
```

Dividir en training set y test set

```{r}
set.seed(2)
index = sample(1:nrow(data), 0.7*nrow(data))
# Creamos el training set
train = data[index,]
# Creamos el test set
test = data[-index,]
# Evaluamos
dim(train)
dim(test)
```

Dividir el training y test set en variables x y

```{r}
set.seed(2)
# Training set
x_train = train%>%select(-famsup)%>%as.matrix
y_train <- train$famsup
#Test set
x_test <- test%>%select(-famsup)%>%as.matrix
y_test <- test$famsup
```



# ========================= #
# REGRESION LASSO LOGISTICA #
# ========================= #

Calcular el lambda optimo

```{r}
set.seed(10)
grid_lasso = 10^seq(10, -3, length = 100)
cv_lasso = cv.glmnet(x = x_train, y = y_train, 
                       family = 'binomial',
                       alpha = 1, 
                       lambda = grid_lasso)
lasso_bestlam = cv_lasso$lambda.min
```

Plot del lambda optimo

```{r}
par("mar"=c(5,5,5,2))
plot(cv_lasso)
title(main = "Tuning parameter apropiado para modelo Lasso", line = 3)
```

Estimar la regresion Lasso

```{r}
lasso_reg = glmnet(x = x_train, y = y_train, 
                  family = 'binomial', 
                  alpha = 1, 
                  lambda = lasso_bestlam)
round(coef(lasso_reg), 4)
```


Crear la función de evaluación

```{r}
# Compute R^2 from true and predicted values
eval_results <- function(true, predicted, df) {
  SSE <- sum((predicted - true)^2)
  SST <- sum((true - mean(true))^2)
  R_square <- 1 - SSE / SST
  RMSE = sqrt(SSE/nrow(df))
  # Model performance metrics
data.frame(
  RMSE = RMSE,
  Rsquare = R_square
)
}
```


Calcular el Adjusted R squared y el RMSE para el training test

```{r}
prediction_lasso_train <- predict(lasso_reg, s = lasso_bestlam, newx = x_train)
eval_results(y_train, prediction_lasso_train, train)
```


Predecir en el test set

```{r}
prediction_lasso_test <- predict(lasso_reg, s = lasso_bestlam, newx = x_test)
eval_results(y_test, prediction_lasso_test, test)
```


```{r}
dim(data)
```


# =================== #
# REGRESION LOGISTICA #
# =================== #

```{r}
log_reg = glm(famsup ~ ., data = train, family = "binomial")
summary(log_reg)
```




